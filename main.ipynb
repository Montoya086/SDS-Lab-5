{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 5\n",
    "**Threat Hunting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 746909\n"
     ]
    }
   ],
   "source": [
    "with open('large_eve.json', 'r') as file:\n",
    "    records = [json.loads(line) for line in file]\n",
    "print(f\"Total records: {len(records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS records: 15749\n"
     ]
    }
   ],
   "source": [
    "dns_records = [record for record in records if record.get('event_type') == 'dns']\n",
    "print(f\"DNS records: {len(dns_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two random DNS records:\n",
      "{\n",
      "  \"timestamp\": \"2017-07-22T17:33:16.661646-0500\",\n",
      "  \"flow_id\": 1327836194150542,\n",
      "  \"pcap_cnt\": 22269,\n",
      "  \"event_type\": \"dns\",\n",
      "  \"vlan\": 110,\n",
      "  \"src_ip\": \"2001:0dbb:0c18:0011:0260:6eff:fe30:0863\",\n",
      "  \"src_port\": 59680,\n",
      "  \"dest_ip\": \"2001:0500:0001:0000:0000:0000:803f:0235\",\n",
      "  \"dest_port\": 53,\n",
      "  \"proto\": \"UDP\",\n",
      "  \"dns\": {\n",
      "    \"type\": \"query\",\n",
      "    \"id\": 15529,\n",
      "    \"rrname\": \"api.wunderground.com\",\n",
      "    \"rrtype\": \"A\",\n",
      "    \"tx_id\": 0\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"timestamp\": \"2017-07-22T17:33:24.990320-0500\",\n",
      "  \"flow_id\": 2022925111925872,\n",
      "  \"pcap_cnt\": 54352,\n",
      "  \"event_type\": \"dns\",\n",
      "  \"vlan\": 110,\n",
      "  \"src_ip\": \"2001:0dbb:0c18:0011:0260:6eff:fe30:0863\",\n",
      "  \"src_port\": 38051,\n",
      "  \"dest_ip\": \"2001:0500:0003:0000:0000:0000:0000:0042\",\n",
      "  \"dest_port\": 53,\n",
      "  \"proto\": \"UDP\",\n",
      "  \"dns\": {\n",
      "    \"type\": \"query\",\n",
      "    \"id\": 58278,\n",
      "    \"rrname\": \"stork79.dropbox.com\",\n",
      "    \"rrtype\": \"A\",\n",
      "    \"tx_id\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTwo random DNS records:\")\n",
    "for record in dns_records[:2]:\n",
    "    print(json.dumps(record, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape: (15749, 18)\n"
     ]
    }
   ],
   "source": [
    "df = pd.json_normalize(dns_records)\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type A records: 2849\n"
     ]
    }
   ],
   "source": [
    "df_type_a = df[df['dns.rrtype'] == 'A']\n",
    "print(f\"\\nType A records: {len(df_type_a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique domains: 177\n"
     ]
    }
   ],
   "source": [
    "unique_domains = df_type_a['dns.rrname'].unique()\n",
    "print(f\"\\nUnique domains: {len(unique_domains)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_common_tld(tld):\n",
    "    common_tlds = ['com', 'org', 'net', 'edu', 'gov', 'mil', 'io', 'co', 'uk', 'ru', 'us', 'eu', 'de', 'fr', 'jp']\n",
    "    return tld.lower() in common_tlds\n",
    "\n",
    "def get_tld(domain):\n",
    "    \"\"\"\n",
    "    source: Claude Sonnet 3.7\n",
    "    prompt: generate a function that extracts the TLD from a domain\n",
    "    \"\"\"\n",
    "    #if domain is empty or not a string, return empty string\n",
    "    if not domain or not isinstance(domain, str):\n",
    "        return ''\n",
    "    \n",
    "    #if domain contains protocol, parse it\n",
    "    if '://' in domain:\n",
    "        parsed_url = urlparse(domain)\n",
    "        domain = parsed_url.netloc\n",
    "    \n",
    "    #if domain contains www, remove it\n",
    "    clean_domain = re.sub(r'^www\\.', '', domain)\n",
    "    \n",
    "    #if domain contains path, remove it\n",
    "    clean_domain = clean_domain.split('/')[0]\n",
    "    \n",
    "    #divide domain by points\n",
    "    parts = clean_domain.split('.')\n",
    "    \n",
    "    #if domain has less than 2 parts, return domain\n",
    "    if len(parts) < 2:\n",
    "        return clean_domain\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        #for cases like example.com\n",
    "        return clean_domain\n",
    "    else:\n",
    "        #for cases like api.wunderground.com or safebrowsing.clients.google.com.home\n",
    "        \n",
    "        #check if domain ends with a custom subdomain (like .home)\n",
    "        if len(parts) > 3 and not is_common_tld(parts[-1]):\n",
    "            #for google.com.home, return home\n",
    "            return parts[-1]\n",
    "        else:\n",
    "            #for api.wunderground.com, return wunderground.com\n",
    "            return f\"{parts[-2]}.{parts[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame with TLDs:\n",
      "                                       domain        domain_tld\n",
      "0                        api.wunderground.com  wunderground.com\n",
      "1                         stork79.dropbox.com       dropbox.com\n",
      "2  hpca-tier2.office.aol.com.ad.aol.aoltw.net         aoltw.net\n",
      "3        safebrowsing.clients.google.com.home              home\n",
      "4                         fxfeeds.mozilla.com       mozilla.com\n"
     ]
    }
   ],
   "source": [
    "df_tld = pd.DataFrame({'domain': unique_domains})\n",
    "df_tld['domain_tld'] = df_tld['domain'].apply(get_tld)\n",
    "print(\"\\nFinal DataFrame with TLDs:\")\n",
    "print(df_tld.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel(model_name='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_domain(domain):\n",
    "    \"\"\"\n",
    "    Classify a domain as DGA (1) or legitimate (0) using Gemini\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a domain security expert. Analyze this domain name and classify it as DGA (Domain Generation Algorithm) or legitimate.\n",
    "    \n",
    "    Domain: {domain}\n",
    "    \n",
    "    DGA Indicators (if ANY of these are present, classify as DGA):\n",
    "    1. Random character sequences (e.g., 'x7k9m2p4')\n",
    "    2. Unusual character combinations (e.g., 'qwerty123', 'abc123')\n",
    "    3. Lack of meaningful words or brand names\n",
    "    4. Unusual length (very long or very short)\n",
    "    5. Suspicious patterns in subdomains\n",
    "    6. Repetitive patterns (e.g., 'aaa', '111')\n",
    "    7. Mixed case usage (e.g., 'aBcDeF')\n",
    "    8. Numbers mixed randomly with letters\n",
    "    9. Unusual TLD combinations\n",
    "    10. Subdomains that look like random strings\n",
    "    \n",
    "    Examples of DGA domains:\n",
    "    - x7k9m2p4.example.com\n",
    "    - abc123xyz.net\n",
    "    - qwertyuiop.asia\n",
    "    - 1234567890.org\n",
    "    - xysad.google.com\n",
    "    - xysad.microsoft.com\n",
    "    - xysad.amazon.com\n",
    "    - xysad.github.com\n",
    "    \n",
    "    Examples of legitimate domains:\n",
    "    - google.com\n",
    "    - microsoft.com\n",
    "    - amazon.com\n",
    "    - github.com\n",
    "    \n",
    "    IMPORTANT:\n",
    "    - If ANY subdomain shows DGA characteristics, classify the entire domain as DGA\n",
    "    - Even if the TLD is legitimate, suspicious subdomains indicate DGA\n",
    "    - Respond with ONLY '1' for DGA or '0' for legitimate\n",
    "    - Be conservative: if in doubt, classify as DGA\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        result = response.text.strip()\n",
    "        return int(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying {domain}: {str(e)}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if domain_tld_dga.csv exists\n",
    "# This workaround is needed because the dataframe is too large to be processed in one go\n",
    "if os.path.exists('domain_tld_dga.csv'):\n",
    "    # Load the dataframe from the csv file\n",
    "    df_tld = pd.read_csv('domain_tld_dga.csv')\n",
    "    \n",
    "    # Create a mask for unclassified domains (is_dga = -1)\n",
    "    unclassified_mask = df_tld['is_dga'] == -1\n",
    "    \n",
    "    # Only classify domains that haven't been classified yet\n",
    "    if unclassified_mask.any():\n",
    "        df_tld.loc[unclassified_mask, 'is_dga'] = df_tld.loc[unclassified_mask, 'domain'].apply(classify_domain)\n",
    "        # Save the dataframe to a csv file\n",
    "        df_tld.to_csv('domain_tld_dga.csv', index=False)\n",
    "        # Reload the dataframe from the csv file\n",
    "        df_tld = pd.read_csv('domain_tld_dga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DGA Domains (after removing duplicates):\n",
      "                                             domain     domain_tld\n",
      "2        hpca-tier2.office.aol.com.ad.aol.aoltw.net            net\n",
      "6                        aolmtcmxm03.office.aol.com            com\n",
      "7       aolmtcmxm02.office.aol.com.ad.aol.aoltw.net            net\n",
      "8                        aolmtcmxm02.office.aol.com            com\n",
      "10      aolmtcmxm03.office.aol.com.ad.aol.aoltw.net            net\n",
      "11                       aolmtcmxm04.office.aol.com            com\n",
      "15      aolmtcmxm04.office.aol.com.ad.aol.aoltw.net            net\n",
      "18                         192.168.22.110phpmyadmin  110phpmyadmin\n",
      "24             192.168.22.110phpmyadmin.localdomain    localdomain\n",
      "27                             proxim.ntkrnlpa.info           info\n",
      "32                      AOLDTCMA04.ad.aol.aoltw.net            net\n",
      "42                tools.google.com.ad.aol.aoltw.net            net\n",
      "43   safebrowsing.clients.google.com.hackerlabs.vpn            vpn\n",
      "54      secure.informaction.com.hsd1.pa.comcast.net            net\n",
      "56             clients1.google.com.ad.aol.aoltw.net            net\n",
      "63           secure.informaction.com.hackerlabs.vpn            vpn\n",
      "67              safebrowsing.clients.google.com.lan            lan\n",
      "84           www.sql-ledger.org.hsd1.pa.comcast.net            net\n",
      "88                                 192.168.26-27.-1             -1\n",
      "130               www.metasploit.com.office.aol.com            com\n",
      "133                  192.168.21.1201.stayonline.net            net\n",
      "139                      r1s6i7.connectivity.me.com            com\n",
      "153          secure.informaction.com.office.aol.com            com\n",
      "160                            vtlfccmfxlkgifuf.com            com\n",
      "161    linkhelp.clients.google.com.ad.aol.aoltw.net            net\n",
      "166                                192.168.21-28.-1             -1\n",
      "167                            ejfodfmfxlkgifuf.xyz            xyz\n",
      "168                           192.168.21-28.-1.home           home\n",
      "169                                 192.168.22.201:           201:\n",
      "171     aoldtcmds01.office.aol.com.ad.aol.aoltw.net            net\n",
      "175                  192.168.22.201:.stayonline.net            net\n",
      "\n",
      "Total unique DGA domains: 31\n"
     ]
    }
   ],
   "source": [
    "dga_domains = df_tld[df_tld['is_dga'] == 1]\n",
    "print(\"\\nDGA Domains (after removing duplicates):\")\n",
    "print(dga_domains[['domain', 'domain_tld']].drop_duplicates())\n",
    "print(f\"\\nTotal unique DGA domains: {len(dga_domains.drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tld = pd.read_csv('domain_tld_dga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tld_list():\n",
    "    try:\n",
    "        df_tlds = pd.read_csv('top-1m.csv', header=None, names=['rank', 'domain'])\n",
    "        tlds = set(df_tlds['domain'].apply(lambda x: x.split('.')[-1].lower()))\n",
    "        return tlds\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading TLD list: {str(e)}\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLD_SET = load_tld_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tld_in_list(tld):\n",
    "    \"\"\"\n",
    "    source: Claude Sonnet 3.7\n",
    "    Prompt: generate a function that checks if a tld is in the top 1M list (top-1m.csv)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return 1 if tld.lower() not in TLD_SET else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking TLD in list: {str(e)}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking TLDs against top 1M list...\n",
      "Error checking TLD in list: 'float' object has no attribute 'lower'\n",
      "\n",
      "Suspicious domains (after removing duplicates):\n",
      "                                             domain     domain_tld\n",
      "3              safebrowsing.clients.google.com.home           home\n",
      "13                                        wpad.home           home\n",
      "18                         192.168.22.110phpmyadmin  110phpmyadmin\n",
      "20              secure.informaction.com.localdomain    localdomain\n",
      "21      safebrowsing.clients.google.com.localdomain    localdomain\n",
      "24             192.168.22.110phpmyadmin.localdomain    localdomain\n",
      "39                                www.theanime.cn.                \n",
      "43   safebrowsing.clients.google.com.hackerlabs.vpn            vpn\n",
      "52                     secure.informaction.com.home           home\n",
      "63           secure.informaction.com.hackerlabs.vpn            vpn\n",
      "66                                             wpad           wpad\n",
      "67              safebrowsing.clients.google.com.lan            lan\n",
      "71                                 \"192.168.206.56\"            56\"\n",
      "88                                 192.168.26-27.-1             -1\n",
      "126                                              FL             FL\n",
      "131                                         saruman        saruman\n",
      "135                                 192.168.21.1201           1201\n",
      "151                           whitecell.localdomain    localdomain\n",
      "163                                 1922.168.22.254            254\n",
      "165                            1922.168.22.254.home           home\n",
      "166                                192.168.21-28.-1             -1\n",
      "168                           192.168.21-28.-1.home           home\n",
      "169                                 192.168.22.201:           201:\n",
      "172                      ntp.ubuntu.com.localdomain    localdomain\n",
      "\n",
      "Total unique suspicious domains: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking TLDs against top 1M list...\")\n",
    "df_tld['tld_not_in_list'] = df_tld['domain_tld'].apply(check_tld_in_list)\n",
    "suspicious_domains = df_tld[df_tld['tld_not_in_list'] == 1]\n",
    "print(\"\\nSuspicious domains (after removing duplicates):\")\n",
    "print(suspicious_domains[['domain', 'domain_tld']].drop_duplicates())\n",
    "print(f\"\\nTotal unique suspicious domains: {len(suspicious_domains.drop_duplicates())}\")\n",
    "#save suspicious_domains to a csv file\n",
    "suspicious_domains.to_csv('suspicious_domains.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tld_creation_date(tld):\n",
    "    try:\n",
    "        w = whois.whois(tld)\n",
    "        if w.creation_date:\n",
    "            if isinstance(w.creation_date, list):\n",
    "                return w.creation_date[0]\n",
    "            return w.creation_date\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting creation date for {tld}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting creation dates for suspicious domains...\n",
      "\n",
      "Suspicious domains with creation dates:\n",
      "                                             domain\n",
      "3              safebrowsing.clients.google.com.home\n",
      "13                                        wpad.home\n",
      "18                         192.168.22.110phpmyadmin\n",
      "20              secure.informaction.com.localdomain\n",
      "21      safebrowsing.clients.google.com.localdomain\n",
      "24             192.168.22.110phpmyadmin.localdomain\n",
      "39                                www.theanime.cn. \n",
      "43   safebrowsing.clients.google.com.hackerlabs.vpn\n",
      "52                     secure.informaction.com.home\n",
      "63           secure.informaction.com.hackerlabs.vpn\n",
      "66                                             wpad\n",
      "67              safebrowsing.clients.google.com.lan\n",
      "71                                 \"192.168.206.56\"\n",
      "88                                 192.168.26-27.-1\n",
      "126                                              FL\n",
      "131                                         saruman\n",
      "135                                 192.168.21.1201\n",
      "151                           whitecell.localdomain\n",
      "163                                 1922.168.22.254\n",
      "165                            1922.168.22.254.home\n",
      "166                                192.168.21-28.-1\n",
      "168                           192.168.21-28.-1.home\n",
      "169                                 192.168.22.201:\n",
      "172                      ntp.ubuntu.com.localdomain\n",
      "\n",
      "Number of suspicious domains with creation dates: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/qnct18y92yz9wqjrkmn7frnh0000gn/T/ipykernel_65701/1896722279.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  suspicious_domains['creation_date'] = suspicious_domains['domain_tld'].apply(get_tld_creation_date)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGetting creation dates for suspicious domains...\")\n",
    "suspicious_domains['creation_date'] = suspicious_domains['domain_tld'].apply(get_tld_creation_date)\n",
    "print(\"\\nSuspicious domains with creation dates:\")\n",
    "print(suspicious_domains[['domain']].drop_duplicates())\n",
    "print(f\"\\nNumber of suspicious domains with creation dates: {len(suspicious_domains[['domain', 'domain_tld', 'creation_date']].drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dga_pattern(domain):\n",
    "    import re\n",
    "    # Pattern for random character sequences\n",
    "    random_pattern = re.compile(r'[a-zA-Z0-9]{8,}')\n",
    "    # Pattern for repetitive characters\n",
    "    repetitive_pattern = re.compile(r'(.)\\1{2,}')\n",
    "    \n",
    "    # Check for random sequences\n",
    "    if random_pattern.search(domain):\n",
    "        return True\n",
    "    # Check for repetitive patterns\n",
    "    if repetitive_pattern.search(domain):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing DGA patterns in suspicious domains...\n",
      "\n",
      "Confirmed DGA domains:\n",
      "                                             domain\n",
      "3              safebrowsing.clients.google.com.home\n",
      "18                         192.168.22.110phpmyadmin\n",
      "20              secure.informaction.com.localdomain\n",
      "21      safebrowsing.clients.google.com.localdomain\n",
      "24             192.168.22.110phpmyadmin.localdomain\n",
      "39                                www.theanime.cn. \n",
      "43   safebrowsing.clients.google.com.hackerlabs.vpn\n",
      "52                     secure.informaction.com.home\n",
      "63           secure.informaction.com.hackerlabs.vpn\n",
      "67              safebrowsing.clients.google.com.lan\n",
      "151                           whitecell.localdomain\n",
      "172                      ntp.ubuntu.com.localdomain\n",
      "\n",
      "Number of confirmed DGA domains: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/qnct18y92yz9wqjrkmn7frnh0000gn/T/ipykernel_65701/271646830.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  suspicious_domains['has_dga_pattern'] = suspicious_domains['domain'].apply(has_dga_pattern)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnalyzing DGA patterns in suspicious domains...\")\n",
    "suspicious_domains['has_dga_pattern'] = suspicious_domains['domain'].apply(has_dga_pattern)\n",
    "confirmed_dga = suspicious_domains[suspicious_domains['has_dga_pattern'] == True]\n",
    "print(\"\\nConfirmed DGA domains:\")\n",
    "print(confirmed_dga[['domain']].drop_duplicates())\n",
    "print(f\"\\nNumber of confirmed DGA domains: {len(confirmed_dga.drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "No se detectaron dominios sospechosos con caracteres aleatorios.\n",
    "\n",
    "Esto puede deberse a varios factores. La causa principal parece ser la variabilidad introducida por la clasificación a través de Gemini. Esta variabilidad está influenciada por la temperatura del modelo y la especificidad del prompt utilizado.\n",
    "\n",
    "Durante las pruebas, se observó que Gemini no siempre clasifica eficazmente los dominios generados por algoritmos (DGA). Con un prompt simple y directo, solo identificó 5 dominios como DGA. Sin embargo, al proporcionar un prompt más detallado y acompañado de ejemplos, la precisión de la clasificación mejoró significativamente.\n",
    "\n",
    "Esto sugiere que la formulación del prompt desempeña un papel crucial en el rendimiento del modelo para tareas de clasificación más complejas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
